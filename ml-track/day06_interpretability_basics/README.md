# Day 06 — Interpretability basics

This notebook introduces **model interpretability basics**, focusing on feature importance and permutation importance for a simple classifier.

## What this project shows

- Training a baseline classifier
- Checking feature importance for a tree model
- Measuring permutation importance for stability
- Using open data (Iris) to make the analysis concrete

## Folder layout

```
.
├── data
│   └── iris.csv
├── notebook.ipynb
├── theory_guide.md
```

## How I run it

1. Install dependencies:
   ```bash
   pip install scikit-learn pandas
   ```
2. Review the theory guide in `theory_guide.md`.
3. Open the notebook and run the cells.

## Data source

The notebook uses the **Iris** dataset (open data) sourced from the seaborn-data repository.
