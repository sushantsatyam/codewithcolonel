{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 03 \u2014 Decision trees + comparison\n",
        "\n",
        "Today I add a **decision tree classifier** and compare it to the Day 02 logistic regression baseline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Goals for this notebook\n",
        "1. Load a real dataset (Breast Cancer Wisconsin).\n",
        "2. Train a logistic regression baseline.\n",
        "3. Train a decision tree and compare metrics.\n",
        "\n",
        "I keep the workflow short but add commentary so each step is clear.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data\n",
        "The scikit-learn dataset loader gives us a clean numeric dataset.\n",
        "I convert it into a DataFrame to make feature inspection easier.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "dataset = load_breast_cancer()\n",
        "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
        "df[\"target\"] = dataset.target\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train/test split\n",
        "I split once so both models see the same train/test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "X = df.drop(columns=[\"target\"])\n",
        "y = df[\"target\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline: logistic regression\n",
        "This mirrors Day 02. We use it as a reference point for the tree.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "log_preds = log_reg.predict(X_test)\n",
        "\n",
        "log_metrics = {\n",
        "    \"model\": \"logistic_regression\",\n",
        "    \"accuracy\": accuracy_score(y_test, log_preds),\n",
        "    \"precision\": precision_score(y_test, log_preds),\n",
        "    \"recall\": recall_score(y_test, log_preds),\n",
        "}\n",
        "log_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Decision tree\n",
        "A decision tree can capture non-linear splits. I keep the depth small\n",
        "to reduce overfitting while still seeing how it compares.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "tree = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "tree_preds = tree.predict(X_test)\n",
        "\n",
        "tree_metrics = {\n",
        "    \"model\": \"decision_tree\",\n",
        "    \"accuracy\": accuracy_score(y_test, tree_preds),\n",
        "    \"precision\": precision_score(y_test, tree_preds),\n",
        "    \"recall\": recall_score(y_test, tree_preds),\n",
        "}\n",
        "tree_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare results\n",
        "I place metrics side-by-side so it is obvious which model wins\n",
        "on this dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "pd.DataFrame([log_metrics, tree_metrics])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}