{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 04 â€” Feature Engineering\n",
        "\n",
        "Feature engineering turns raw columns into signals a model can learn from.\n",
        "\n",
        "We will cover:\n",
        "- Handling missing values\n",
        "- Encoding categorical variables\n",
        "- Scaling numeric features\n",
        "- Creating interaction/ratio features\n",
        "- Building a repeatable preprocessing pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Create a mixed-type dataset\n",
        "We will simulate a small dataset with numeric, categorical, and missing values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "customers = pd.DataFrame(\n",
        "    {\n",
        "        \"age\": [25, 32, 47, None, 52, 23, 39, 41, None, 36],\n",
        "        \"income\": [48000, 62000, 72000, 51000, None, 39000, 68000, 59000, 61000, 65000],\n",
        "        \"region\": [\"north\", \"south\", \"west\", \"east\", \"north\", \"south\", \"west\", \"west\", \"east\", \"north\"],\n",
        "        \"is_premium\": [0, 1, 1, 0, 1, 0, 1, 1, 0, 1],\n",
        "    }\n",
        ")\n",
        "\n",
        "customers.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Add a simple engineered feature\n",
        "Ratio features often capture behavior better than raw values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "customers[\"income_per_age\"] = customers[\"income\"] / (customers[\"age\"] + 1)\n",
        "customers.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Define preprocessing steps\n",
        "We treat numeric and categorical columns differently.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "X = customers.drop(columns=\"is_premium\")\n",
        "y = customers[\"is_premium\"]\n",
        "\n",
        "numeric_features = [\"age\", \"income\", \"income_per_age\"]\n",
        "categorical_features = [\"region\"]\n",
        "\n",
        "numeric_transformer = Pipeline(\n",
        "    [\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    [\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    [\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Train a model with preprocessing in a pipeline\n",
        "Pipelines make preprocessing repeatable and avoid data leakage.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "model = Pipeline(\n",
        "    [\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"classifier\", LogisticRegression()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "accuracy_score(y_test, preds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) What to do next\n",
        "Once features are in good shape, the next improvement often comes from\n",
        "**hyperparameter tuning** and model selection (Day 05).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}