{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 06 — RAG basics (lightweight)\n",
        "\n",
        "Retrieval-Augmented Generation (RAG) answers questions using a local knowledge base.\n",
        "\n",
        "We will cover:\n",
        "- Loading documents\n",
        "- Simple vectorization with TF-IDF\n",
        "- Retrieving relevant chunks\n",
        "- Asking the model with context\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Load documents\n",
        "We’ll use a small dataset of penguin facts.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "penguins = pd.read_csv(\"data/penguins.csv\")\n",
        "penguins = penguins.dropna(subset=[\"species\", \"island\", \"body_mass_g\"])\n",
        "\n",
        "penguins[\"doc\"] = (\n",
        "    \"Species: \"\n",
        "    + penguins[\"species\"]\n",
        "    + \". Island: \"\n",
        "    + penguins[\"island\"]\n",
        "    + \". Body mass (g): \"\n",
        "    + penguins[\"body_mass_g\"].astype(str)\n",
        ")\n",
        "\n",
        "penguins[[\"species\", \"island\", \"body_mass_g\"]].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Build a simple retriever\n",
        "We use TF-IDF to find similar rows.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(penguins[\"doc\"])\n",
        "\n",
        "question = \"Which penguin species is the heaviest, and where is it found?\"\n",
        "q_vec = vectorizer.transform([question])\n",
        "\n",
        "scores = cosine_similarity(q_vec, X).flatten()\n",
        "\n",
        "top_idx = scores.argsort()[-3:][::-1]\n",
        "context = \"\\n\".join(penguins.iloc[top_idx][\"doc\"].tolist())\n",
        "context\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Ask the model with context\n",
        "We pass the retrieved context to the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Answer the question using ONLY the context.\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "answer = client.responses.create(model=MODEL, input=prompt, temperature=0.2).output_text\n",
        "answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) What to do next\n",
        "Explore better embeddings, chunking, and reranking for stronger RAG performance.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}