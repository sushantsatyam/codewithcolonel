{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 02 — Prompt chaining (planner → executor → critic)\n",
        "\n",
        "This notebook builds a tiny chain: a planner creates steps, executors fill them in, and a critic reviews the final answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from pathlib import Path\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "PROMPTS_DIR = Path(\"prompts\")\n",
        "\n",
        "def load_prompt(name: str) -> str:\n",
        "    return (PROMPTS_DIR / name).read_text()\n",
        "\n",
        "def render(template: str, **kwargs: str) -> str:\n",
        "    text = template\n",
        "    for key, value in kwargs.items():\n",
        "        text = text.replace(f\"{{{key}}}\", value)\n",
        "    return text\n",
        "\n",
        "def call_openai(prompt: str, model: str = \"gpt-4o-mini\") -> str:\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "async def call_openai_async(prompt: str, model: str = \"gpt-4o-mini\") -> str:\n",
        "    return await asyncio.to_thread(call_openai, prompt, model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "request = \"Design a one-week plan to learn the basics of neural networks.\"\n",
        "\n",
        "planner_prompt = render(\n",
        "    load_prompt(\"planner.txt\"),\n",
        "    request=request,\n",
        ")\n",
        "\n",
        "plan = call_openai(planner_prompt)\n",
        "plan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sequential execution\n",
        "Each step is completed one at a time. This makes it easier to keep context, but it can be slower."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "steps = [line for line in plan.splitlines() if line.strip()]\n",
        "\n",
        "executor_template = load_prompt(\"executor.txt\")\n",
        "\n",
        "sequential_results = []\n",
        "for step in steps:\n",
        "    prompt = render(executor_template, context=request, step=step)\n",
        "    sequential_results.append(call_openai(prompt))\n",
        "\n",
        "sequential_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parallel execution\n",
        "If steps are independent, they can run concurrently to save time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def run_parallel(steps_list: list[str]) -> list[str]:\n",
        "    tasks = []\n",
        "    for step in steps_list:\n",
        "        prompt = render(executor_template, context=request, step=step)\n",
        "        tasks.append(asyncio.create_task(call_openai_async(prompt)))\n",
        "    return await asyncio.gather(*tasks)\n",
        "\n",
        "parallel_results = await run_parallel(steps)\n",
        "parallel_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Critic review\n",
        "A quick sanity check on the combined answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_answer = \"\\n\".join(parallel_results)\n",
        "critic_prompt = render(load_prompt(\"critic.txt\"), answer=combined_answer)\n",
        "critic_feedback = call_openai(critic_prompt)\n",
        "critic_feedback"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
