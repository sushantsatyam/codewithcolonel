{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 01 â€” Prompting styles + simple agent execution\n",
        "\n",
        "This notebook compares **zero-shot**, **few-shot**, and **role prompting**, then runs them **sequentially** and **in parallel** to show the difference in execution style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from pathlib import Path\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "PROMPTS_DIR = Path(\"prompts\")\n",
        "\n",
        "def load_prompt(filename: str) -> str:\n",
        "    return (PROMPTS_DIR / filename).read_text()\n",
        "\n",
        "def render_prompt(template: str, question: str) -> str:\n",
        "    return template.replace(\"{question}\", question)\n",
        "\n",
        "def call_openai(prompt: str, model: str = \"gpt-4o-mini\") -> str:\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "async def call_openai_async(prompt: str, model: str = \"gpt-4o-mini\") -> str:\n",
        "    return await asyncio.to_thread(call_openai, prompt, model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"Give me a 3-step plan to build a small ML project.\"\n",
        "\n",
        "templates = {\n",
        "    \"zero_shot\": load_prompt(\"zero_shot.txt\"),\n",
        "    \"few_shot\": load_prompt(\"few_shot.txt\"),\n",
        "    \"role_prompt\": load_prompt(\"role_prompt.txt\"),\n",
        "}\n",
        "\n",
        "rendered_prompts = {\n",
        "    name: render_prompt(template, question)\n",
        "    for name, template in templates.items()\n",
        "}\n",
        "rendered_prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sequential execution\n",
        "Each prompt is run one after another. This is the simplest agent pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sequential_results = {}\n",
        "for name, prompt in rendered_prompts.items():\n",
        "    sequential_results[name] = call_openai(prompt)\n",
        "\n",
        "sequential_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parallel execution\n",
        "The prompts are sent concurrently. This is useful when tasks are independent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def run_parallel(prompts: dict) -> dict:\n",
        "    tasks = {\n",
        "        name: asyncio.create_task(call_openai_async(prompt))\n",
        "        for name, prompt in prompts.items()\n",
        "    }\n",
        "    return {name: await task for name, task in tasks.items()}\n",
        "\n",
        "parallel_results = await run_parallel(rendered_prompts)\n",
        "parallel_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick comparison\n",
        "I eyeball these outputs to see how different prompts shape the answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for name, output in parallel_results.items():\n",
        "    print(f\"\\n--- {name} ---\\n{output}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
